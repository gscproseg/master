

import streamlit as st

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title= "MLens",
    page_icon= "üß†",  # Defina o √≠cone da p√°gina como um emoji de tubar√£o
    layout="wide",  # Defina o layout como "wide" para aproveitar melhor o espa√ßo na tela
    initial_sidebar_state="collapsed"  # Defina a barra lateral como colapsada
)

# Cria√ß√£o das guias
tab1, tab2, tab3, tab4 = st.tabs(["MLens", "Detec√ß√£o em Imagens", "Detec√ß√£o em V√≠deo", "Detec√£o em RT"])

# Conte√∫do da p√°gina "Home"
with tab1:
    st.subheader("Bem-vindo ao MLens")
    # Adicionar a imagem ao espa√ßo em branco
    st.image("./Mlens.png", use_column_width=True)  #  caminho da sua imagem

# Adicione as informa√ß√µes adicionais
st.write("Desenvolvido por LIMT - Ufra e [Carneiro, G.S](http://lattes.cnpq.br/3771047626259544)")

#######################################################

with tab2:

    st.header("Detec√ß√£o em Imagens")
    
    from yolov5_predictions import YOLO_Pred
    from PIL import Image
    import numpy as np

    st.write('Por favor, carregue a imagem para obter a identifica√ß√£o')

    with st.spinner('Por favor, aguarde enquanto analisamos a sua imagem'):
        yolo = YOLO_Pred(onnx_model='./best.onnx',
                        data_yaml='./data.yaml')
        #st.balloons()

    def upload_image():
        # Upload Image
        image_file = st.file_uploader(label='Enviar Imagem')
        if image_file is not None:
            size_mb = image_file.size / (1024 ** 2)
            file_details = {"filename": image_file.name,
                            "filetype": image_file.type,
                            "filesize": "{:,.2f} MB".format(size_mb)}
            #st.json(file_details)
            # validate file
            if file_details['filetype'] in ('image/png', 'image/jpeg'):
                st.success('Tipo de arquivo imagem VALIDO (png ou jpeg)')
                return {"file": image_file,
                        "details": file_details}

            else:
                st.error('Tipo de arquivo de imagem INVALIDO')
                st.error('Envie apenas arquivos nos formatos png, jpg e jpeg')
                return None

    def main():
        object = upload_image()

        if object:
            prediction = False
            image_obj = Image.open(object['file'])

            col1, col2 = st.columns(2)#

            with col1:
                st.info('Pr√©-visualiza√ß√£o da imagem')
                st.image(image_obj)#

            with col2:
                st.subheader('Confira abaixo os detalhes do arquivo')
                st.json(object['details'])
                button = st.button('Descubra qual o Myxozo√°rio pode estar presente em sua imagem')
                if button:
                    with st.spinner("""
                    Obtendo Objets de imagem. Aguarde
                    """):
                        # below command will convert
                        # obj to array
                        image_array = np.array(image_obj)
                        pred_img = yolo.predictions(image_array)
                        pred_img_obj = Image.fromarray(pred_img)
                        prediction = True

            if prediction:
                st.subheader("Imagem com a possivel detec√ß√£o")
                st.caption("Detec√ß√£o de Myxozo√°rios")
                st.image(pred_img_obj)

    if __name__ == "__main__":
         main()

pass



# Conte√∫do da p√°gina "Video"
import time  # Importe o m√≥dulo time

with tab3:
    st.header("Detec√ß√£o em Video")

    # Fun√ß√£o para detec√ß√£o em v√≠deo
    def detect_video(upload_file):
        # Importa√ß√µes necess√°rias
        import cv2
        import tempfile
        from pathlib import Path

        # Carrega o modelo YOLO e outros recursos
        yolo = YOLO_Pred(onnx_model='./best.onnx', data_yaml='./data.yaml')

        # Salva o v√≠deo temporariamente
        temp_video_path = Path(tempfile.NamedTemporaryFile().name)
        with open(temp_video_path, 'wb') as temp_file:
            temp_file.write(upload_file.read())

        # Inicia a captura de v√≠deo
        video_capture = cv2.VideoCapture(str(temp_video_path))

        start_time = time.time()  # Marca o tempo de in√≠cio da detec√ß√£o

        while True:
            ret, frame = video_capture.read()

            # Verifica se a captura de v√≠deo foi bem-sucedida
            if not ret:
                break

            # Converte o frame para o formato esperado pela fun√ß√£o de detec√ß√£o
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # Realiza a detec√ß√£o de objetos
            pred_frame = yolo.predictions(frame_rgb)

            # Exibe o frame com as detec√ß√µes no Streamlit
            st.image(pred_frame, channels='RGB', use_column_width=True)

            # Limita o tempo de execu√ß√£o do loop (por exemplo, 30 segundos)
            if time.time() - start_time > 30:
                break

        # Libera a captura de v√≠deo
        video_capture.release()

    # Upload de arquivo de v√≠deo
    uploaded_file = st.file_uploader(label='Enviar V√≠deo', type=['mp4', 'avi'])

    # Bot√£o para iniciar a detec√ß√£o em v√≠deo
    if uploaded_file is not None:
        if st.button('Iniciar Detec√ß√£o em V√≠deo'):
            detect_video(uploaded_file)

pass


with tab4:
    st.subheader("N√£o dispon√≠vel nesta Vers√£o, Aguarde!")

    import cv2
    import numpy as np
    import yaml
    
    # Fun√ß√£o para realizar a pr√©-processamento da imagem
    def preprocess(image):
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (640, 640))
        image = image.astype(np.float32)
        image /= 255.0
        image = np.transpose(image, (2, 0, 1))
        image = np.expand_dims(image, axis=0)
        return image
    
    # Fun√ß√£o para realizar a p√≥s-processamento da sa√≠da do modelo
    def postprocess(outputs, img_shape):
        # A fun√ß√£o de p√≥s-processamento pode variar com base no formato da sa√≠da do seu modelo.
        # Aqui voc√™ deve converter as sa√≠das em caixas delimitadoras, confid√™ncias e classes.
        pass  # Implementar de acordo com seu modelo
    
    # Carregar o modelo ONNX
    session = onnxruntime.InferenceSession('best.onnx')
    
    # Carregar o arquivo data.yaml
    with open('data.yaml', 'r') as f:
        data = yaml.safe_load(f)
    
    # Inicializar a captura de v√≠deo
    cap = cv2.VideoCapture(0)  # 0 para a webcam padr√£o
    
    # Verificar se a captura de v√≠deo foi inicializada corretamente
    if not cap.isOpened():
        print("Erro ao abrir a webcam.")
        exit()
    
    while True:
        # Capturar um quadro da webcam
        ret, frame = cap.read()
    
        # Verificar se o quadro foi capturado corretamente
        if not ret:
            print("Erro ao capturar o quadro.")
            break
    
        # Pr√©-processar o quadro
        input_image = preprocess(frame)
    
        # Realizar a infer√™ncia
        outputs = session.run(None, {session.get_inputs()[0].name: input_image})
    
        # P√≥s-processar a sa√≠da
        boxes, confidences, class_ids = postprocess(outputs, frame.shape)
    
        # Desenhar as caixas delimitadoras no quadro
        for box, conf, class_id in zip(boxes, confidences, class_ids):
            x, y, w, h = box
            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            cv2.putText(frame, f"{data['names'][class_id]}: {conf:.2f}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
    
        # Exibir o quadro com as detec√ß√µes
        cv2.imshow('Webcam - YOLOv5', frame)
    
        # Pressionar 'q' para sair do loop
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    # Liberar a captura de v√≠deo e fechar todas as janelas
    cap.release()
    cv2.destroyAllWindows()


#########################################################################################


